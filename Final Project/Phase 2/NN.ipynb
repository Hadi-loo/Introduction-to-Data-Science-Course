{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import keras_tuner as kt\n",
    "import ast\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the preprocessed dataset from phase 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_name</th>\n",
       "      <th>album_name</th>\n",
       "      <th>artists</th>\n",
       "      <th>explicit</th>\n",
       "      <th>key</th>\n",
       "      <th>mode</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>loudness</th>\n",
       "      <th>...</th>\n",
       "      <th>week_of_year</th>\n",
       "      <th>day</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>day_of_year</th>\n",
       "      <th>duration_mins</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>artist_count</th>\n",
       "      <th>genre_count</th>\n",
       "      <th>track_genre</th>\n",
       "      <th>popularity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ode To The Mets</td>\n",
       "      <td>The New Abnormal</td>\n",
       "      <td>['The Strokes']</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.4280</td>\n",
       "      <td>0.617</td>\n",
       "      <td>-5.424</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>Friday</td>\n",
       "      <td>101</td>\n",
       "      <td>5.863117</td>\n",
       "      <td>351787</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>['alt-rock', 'garage']</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Glaciers</td>\n",
       "      <td>Bloom</td>\n",
       "      <td>['Lights &amp; Motion']</td>\n",
       "      <td>False</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0789</td>\n",
       "      <td>0.160</td>\n",
       "      <td>-18.144</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>Friday</td>\n",
       "      <td>33</td>\n",
       "      <td>2.939550</td>\n",
       "      <td>176373</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>['ambient']</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Uber Pussy</td>\n",
       "      <td>Pink Season</td>\n",
       "      <td>['Pink Guy']</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.8700</td>\n",
       "      <td>0.597</td>\n",
       "      <td>-6.320</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>4</td>\n",
       "      <td>1.956017</td>\n",
       "      <td>117361</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>['comedy']</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2002</td>\n",
       "      <td>Speak Your Mind (Deluxe)</td>\n",
       "      <td>['Anne-Marie']</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.6970</td>\n",
       "      <td>0.683</td>\n",
       "      <td>-2.881</td>\n",
       "      <td>...</td>\n",
       "      <td>17</td>\n",
       "      <td>27</td>\n",
       "      <td>Friday</td>\n",
       "      <td>117</td>\n",
       "      <td>3.116450</td>\n",
       "      <td>186987</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>['dance', 'house', 'pop']</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Monsters You Made (feat. Chris Martin)</td>\n",
       "      <td>Twice As Tall</td>\n",
       "      <td>['Burna Boy', 'Chris Martin']</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.6710</td>\n",
       "      <td>0.646</td>\n",
       "      <td>-7.513</td>\n",
       "      <td>...</td>\n",
       "      <td>33</td>\n",
       "      <td>13</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>226</td>\n",
       "      <td>3.625683</td>\n",
       "      <td>217541</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>['dancehall']</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               track_name                album_name  \\\n",
       "0                         Ode To The Mets          The New Abnormal   \n",
       "1                                Glaciers                     Bloom   \n",
       "2                              Uber Pussy               Pink Season   \n",
       "3                                    2002  Speak Your Mind (Deluxe)   \n",
       "4  Monsters You Made (feat. Chris Martin)             Twice As Tall   \n",
       "\n",
       "                         artists  explicit  key  mode  time_signature  \\\n",
       "0                ['The Strokes']     False    1     0             4.0   \n",
       "1            ['Lights & Motion']     False    7     1             4.0   \n",
       "2                   ['Pink Guy']      True    7     1             4.0   \n",
       "3                 ['Anne-Marie']     False    1     0             4.0   \n",
       "4  ['Burna Boy', 'Chris Martin']      True    7     0             4.0   \n",
       "\n",
       "   danceability  energy  loudness  ...  week_of_year  day  day_of_week  \\\n",
       "0        0.4280   0.617    -5.424  ...            15   10       Friday   \n",
       "1        0.0789   0.160   -18.144  ...             5    2       Friday   \n",
       "2        0.8700   0.597    -6.320  ...             1    4    Wednesday   \n",
       "3        0.6970   0.683    -2.881  ...            17   27       Friday   \n",
       "4        0.6710   0.646    -7.513  ...            33   13     Thursday   \n",
       "\n",
       "   day_of_year  duration_mins  duration_ms artist_count genre_count  \\\n",
       "0          101       5.863117       351787            1           2   \n",
       "1           33       2.939550       176373            1           1   \n",
       "2            4       1.956017       117361            1           1   \n",
       "3          117       3.116450       186987            1           3   \n",
       "4          226       3.625683       217541            2           1   \n",
       "\n",
       "                 track_genre  popularity  \n",
       "0     ['alt-rock', 'garage']          67  \n",
       "1                ['ambient']          49  \n",
       "2                 ['comedy']          39  \n",
       "3  ['dance', 'house', 'pop']          82  \n",
       "4              ['dancehall']          45  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('dataset.csv')\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4724 entries, 0 to 4723\n",
      "Data columns (total 36 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   track_name        4724 non-null   object \n",
      " 1   album_name        4724 non-null   object \n",
      " 2   artists           4724 non-null   object \n",
      " 3   explicit          4724 non-null   bool   \n",
      " 4   key               4724 non-null   int64  \n",
      " 5   mode              4724 non-null   int64  \n",
      " 6   time_signature    4724 non-null   float64\n",
      " 7   danceability      4724 non-null   float64\n",
      " 8   energy            4724 non-null   float64\n",
      " 9   loudness          4724 non-null   float64\n",
      " 10  speechiness       4724 non-null   float64\n",
      " 11  acousticness      4724 non-null   float64\n",
      " 12  instrumentalness  4724 non-null   float64\n",
      " 13  liveness          4724 non-null   float64\n",
      " 14  valence           4724 non-null   float64\n",
      " 15  tempo             4724 non-null   float64\n",
      " 16  track_id          4724 non-null   object \n",
      " 17  album_id          4724 non-null   object \n",
      " 18  artist_ids        4724 non-null   object \n",
      " 19  track_number      4724 non-null   int64  \n",
      " 20  disc_number       4724 non-null   int64  \n",
      " 21  release_date      4724 non-null   object \n",
      " 22  decade            4724 non-null   int64  \n",
      " 23  year              4724 non-null   int64  \n",
      " 24  quarter           4724 non-null   int64  \n",
      " 25  month             4724 non-null   int64  \n",
      " 26  week_of_year      4724 non-null   int64  \n",
      " 27  day               4724 non-null   int64  \n",
      " 28  day_of_week       4724 non-null   object \n",
      " 29  day_of_year       4724 non-null   int64  \n",
      " 30  duration_mins     4724 non-null   float64\n",
      " 31  duration_ms       4724 non-null   int64  \n",
      " 32  artist_count      4724 non-null   int64  \n",
      " 33  genre_count       4724 non-null   int64  \n",
      " 34  track_genre       4724 non-null   object \n",
      " 35  popularity        4724 non-null   int64  \n",
      "dtypes: bool(1), float64(11), int64(15), object(9)\n",
      "memory usage: 1.3+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove ID columns because they are not useful for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['track_id', 'album_id', 'artist_ids'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "track_name: object\n",
      "album_name: object\n",
      "artists: object\n",
      "release_date: object\n",
      "day_of_week: object\n",
      "track_genre: object\n"
     ]
    }
   ],
   "source": [
    "non_numeric_cols = data.select_dtypes(exclude=['int', 'float', 'bool']).columns\n",
    "for col in non_numeric_cols:\n",
    "    print(f'{col}: {data[col].dtype}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we extracted the date information, we can remove the original date columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['release_date'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "track_name: object\n",
      "album_name: object\n",
      "artists: object\n",
      "day_of_week: object\n",
      "track_genre: object\n"
     ]
    }
   ],
   "source": [
    "non_numeric_cols = data.select_dtypes(exclude=['int', 'float', 'bool']).columns\n",
    "for col in non_numeric_cols:\n",
    "    print(f'{col}: {data[col].dtype}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['track_genre'] = data['track_genre'].apply(lambda x: ast.literal_eval(x))\n",
    "data['artists'] = data['artists'].apply(lambda x: ast.literal_eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique genres: 111\n"
     ]
    }
   ],
   "source": [
    "genres = set()\n",
    "for genre_list in data['track_genre']:\n",
    "    for genre in genre_list:\n",
    "        genres.add(genre)\n",
    "print(f'Unique genres: {len(genres)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlb = MultiLabelBinarizer()\n",
    "\n",
    "# one_hot_genres = mlb.fit_transform(data['track_genre'])\n",
    "# one_hot_df = pd.DataFrame(one_hot_genres, columns=mlb.classes_)\n",
    "# data = pd.concat([data, one_hot_df], axis=1)\n",
    "data = data.drop(columns=['track_genre'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "track_name: object\n",
      "album_name: object\n",
      "artists: object\n",
      "day_of_week: object\n"
     ]
    }
   ],
   "source": [
    "non_numeric_cols = data.select_dtypes(exclude=['int', 'float', 'bool']).columns\n",
    "for col in non_numeric_cols:\n",
    "    print(f'{col}: {data[col].dtype}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns=['track_name', 'album_name', 'artists', 'day_of_week'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(columns=['popularity'])\n",
    "y = data['popularity']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3: Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Principal Component Analysis (PCA)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns after PCA reduction: 1\n",
      "Number of columns in the origianl Dataset: 26\n",
      "Reduction Ratio 0.038461538461538464 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=0.9, random_state=31)\n",
    "X_reduced = pca.fit_transform(X)\n",
    "pca.explained_variance_ratio_\n",
    "X_reduced_df = pd.DataFrame(X_reduced, columns=[f'PC{i}' for i in range(1, X_reduced.shape[1] + 1)])\n",
    "\n",
    "# print(selected_columns)\n",
    "print(\"Number of columns after PCA reduction:\", X_reduced_df.columns.size)\n",
    "print(\"Number of columns in the origianl Dataset:\", X.columns.size)\n",
    "print(\"Reduction Ratio\", X_reduced_df.columns.size / X.columns.size, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999981989402316"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cumsum = np.cumsum(pca.explained_variance_ratio_)\n",
    "cumsum[-1]\n",
    "# cumsum.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Principal Component  Explained Variance  Explained Variance Ratio\n",
      "0                 PC1        8.237030e+09                  0.999998\n"
     ]
    }
   ],
   "source": [
    "variance_df = pd.DataFrame({\n",
    "    'Principal Component': [f'PC{i}' for i in range(1, len(pca.explained_variance_) + 1)],\n",
    "    'Explained Variance': pca.explained_variance_,\n",
    "    'Explained Variance Ratio': pca.explained_variance_ratio_\n",
    "})\n",
    "\n",
    "# Print the DataFrame\n",
    "print(variance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correspondnig variances of each feature with the first PCA component:\n",
      "    - duration_ms: 0.9999999996663541\n",
      "    - duration_mins: 1.6666666661105896e-05\n",
      "    - tempo: 4.271553709804668e-06\n",
      "    - week_of_year: 3.2466207363977965e-06\n",
      "    - instrumentalness: 5.534170259199161e-07\n",
      "    - time_signature: 1.620077782192154e-07\n",
      "    - key: 1.1167802772071055e-07\n",
      "    - liveness: 6.572747963548224e-08\n",
      "    - disc_number: 3.9183034141126226e-09\n",
      "    - quarter: -3.6064519225345725e-08\n",
      "    - genre_count: -3.747643092294849e-08\n",
      "    - speechiness: -1.3603656953052994e-07\n",
      "    - acousticness: -1.3713955614105753e-07\n",
      "    - danceability: -1.590149921040909e-07\n",
      "    - energy: -1.6694851393590743e-07\n",
      "    - mode: -2.0589034529113577e-07\n",
      "    - month: -2.6014652318361355e-07\n",
      "    - artist_count: -2.6734484001897374e-07\n",
      "    - explicit: -3.6942340314521675e-07\n",
      "    - valence: -4.932788648973499e-07\n",
      "    - day: -2.914150958696777e-06\n",
      "    - track_number: -5.294210180773837e-06\n",
      "    - loudness: -8.002252583441901e-06\n",
      "    - year: -8.611999844439335e-06\n",
      "    - decade: -8.64155958548225e-06\n",
      "    - day_of_year: -1.0503482864711481e-05\n"
     ]
    }
   ],
   "source": [
    "print(\"Correspondnig variances of each feature with the first PCA component:\")\n",
    "selected_columns = X.columns[pca.components_[0].argsort()[::-1]]\n",
    "for col in selected_columns:\n",
    "    print(f\"    - {col}: {pca.components_[0][X.columns.get_loc(col)]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = data.select_dtypes(exclude=['int', 'float']).columns\n",
    "numerical_features = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "X_processed = preprocessor.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_processed, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_numeric_cols = data.select_dtypes(exclude=['int', 'float', 'bool']).columns\n",
    "for col in non_numeric_cols:\n",
    "    print(f'{col}: {data[col].dtype}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(X_train.shape[1],)),  # First hidden layer with 128 neurons\n",
    "    Dropout(0.2),  # Dropout layer to prevent overfitting\n",
    "    Dense(64, activation='relu'),  # Second hidden layer with 64 neurons\n",
    "    Dropout(0.2),  # Dropout layer\n",
    "    Dense(32, activation='relu'),  # Third hidden layer with 32 neurons\n",
    "    Dense(1)  # Output layer with 1 neuron for regression\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='mean_squared_error',  # MSE is a common loss function for regression\n",
    "              metrics=['mean_absolute_error'])  # MAE is a useful metric for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_and_predict(model, X_train, y_train, X_test, y_test, epochs=20, validation_split=0.2, batch_size=10):\n",
    "    history = model.fit(X_train, y_train, epochs=epochs, validation_split=validation_split, batch_size=batch_size)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    return history, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_train, y_train, X_test, y_test):\n",
    "    history, y_pred = fit_and_predict(model, X_train, y_train, X_test, y_test)\n",
    "\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    print(f'Mean Squared Error: {mse}')\n",
    "    print(f'R-squared: {r2}')\n",
    "\n",
    "    plt.figure(figsize=(14, 5))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['loss'], label='Train Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Model Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend(loc='upper right')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.scatter(y_test, y_pred, alpha=0.3)\n",
    "    plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)\n",
    "    plt.title('True vs Predicted Popularity')\n",
    "    plt.xlabel('True Values')\n",
    "    plt.ylabel('Predictions')\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=hp.Int('units_1', min_value=32, max_value=256, step=32), activation='relu', input_shape=(X_train.shape[1],)))\n",
    "    model.add(Dense(units=hp.Int('units_2', min_value=32, max_value=256, step=32), activation='relu'))\n",
    "    model.add(Dense(units=hp.Int('units_3', min_value=32, max_value=256, step=32), activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(hp.Choice('learning_rate', [1e-4, 1e-3, 1e-2])), loss='mse', metrics=['mse'])\n",
    "    return model\n",
    "\n",
    "tuner = kt.RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_loss',\n",
    "    max_trials=10,\n",
    "    executions_per_trial=3,\n",
    "    directory='my_dir',\n",
    "    project_name='tune_keras')\n",
    "\n",
    "tuner.search(X_train, y_train, epochs=15, validation_split=0.2, batch_size=32)\n",
    "\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(f\"\"\"\n",
    "The hyperparameter search is complete. The optimal number of units in the first layer is {best_hps.get('units_1')},\n",
    "the second layer is {best_hps.get('units_2')}, the third layer is {best_hps.get('units_3')}, and the optimal learning rate for the optimizer\n",
    "is {best_hps.get('learning_rate')}.\n",
    "\"\"\")\n",
    "\n",
    "model = tuner.hypermodel.build(best_hps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(model, X_train, y_train, X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
